[
{
	"uri": "//localhost:1313/",
	"title": "Event-Driven Architecture with EC2, MSK, ElastiCache và RDS",
	"tags": [],
	"description": "",
	"content": "Xây dựng Kiến trúc Hướng Sự kiện với AWS Tổng quan Trong bài thực hành này, bạn sẽ xây dựng một kiến trúc hướng sự kiện phức tạp trên AWS bằng cách sử dụng các dịch vụ: EC2, Amazon MSK (Kafka), RDS, và ElastiCache. Ngoài ra, bạn sẽ học cách triển khai chiến lược giám sát hệ thống và tối ưu hóa chi phí vận hành.\nPhòng lab hướng dẫn từng bước để thiết kế, triển khai và tối ưu hóa một quy trình xử lý không đồng bộ theo kiến trúc hướng sự kiện với khả năng mở rộng, chống lỗi, và dễ quan sát.\nMục tiêu chính Thiết kế kiến trúc với Producer và Consumer tách biệt rõ ràng. Đảm bảo eventual consistency bằng mô hình Event-Driven. Đồng bộ dữ liệu giữa các service thông qua Debezium. Cải thiện hiệu suất hệ thống bằng cách áp dụng caching với ElastiCache. Và chúng ta sẽ thực hiện theo kiến trúc như ảnh bên dưới: Yêu cầu trước: Bạn cần có kiến thức cơ bản về EC2, IAM, Kafka, Redis, cũng như hiểu biết về định dạng JSON, cơ chế retry, và các mô hình xử lý bất đồng bộ (async patterns).\nCác dịch vụ chính EC2 (Elastic Compute Cloud) Dịch vụ máy chủ ảo linh hoạt cho phép triển khai ứng dụng trên hạ tầng cloud có thể mở rộng và quản lý được.\nAmazon MSK (Managed Streaming for Apache Kafka) Dịch vụ Kafka được quản lý hoàn toàn bởi AWS, giúp dễ dàng triển khai hệ thống pub-sub và event streaming.\nAmazon RDS (Relational Database Service) Dịch vụ cơ sở dữ liệu quan hệ được quản lý, hỗ trợ nhiều engine như PostgreSQL, MySQL, giúp dễ dàng vận hành, sao lưu và mở rộng.\nAmazon ElastiCache Dịch vụ caching trong bộ nhớ giúp giảm độ trễ truy vấn và tăng tốc độ phản hồi của hệ thống thông qua Redis hoặc Memcached.\nAmazon CloudWatch Nền tảng giám sát tập trung của AWS. Được sử dụng để:\nGhi nhật ký hoạt động và lỗi Theo dõi độ trễ, tần suất lỗi, hiệu năng dịch vụ (RDS, MSK, EC2, ElastiCache) Thiết lập cảnh báo và dashboards Truy vấn log qua CloudWatch Logs Insights Monitoring \u0026amp; Cost Optimization Sử dụng CloudWatch Metrics, Logs và Alarms để theo dõi toàn bộ hệ thống. Phân tích chi phí bằng AWS Cost Explorer. Tối ưu hóa vận hành thông qua truy vấn log và phân tích hành vi hệ thống. Nội dung thực hành Tạo tài nguyên mạng AWS Triển khai ứng dụng đầu tiên ở Public Subnet Tạo cơ sở dữ liệu trong Private Database Subnet Khởi tạo tài nguyên Kafka/Redis ở Private Middleware Subnet Triển khai backend service tại Private Application Subnet Routing API bằng Kong Gateway Thực hiện các API của các dịch vụ backend Thiết lập giám sát và logging với CloudWatch Tối ưu hóa chi phí và hiệu suất "
},
{
	"uri": "//localhost:1313/1-creating-networking-resource-aws/",
	"title": "Tạo tài nguyên mạng AWS",
	"tags": [],
	"description": "",
	"content": "Nội dung:\nTạo VPC Tạo subnets Tạo Route tables Tạo NAT gateway Kết quả Tạo VPC Vào VPC Console. Chọn region, ví dụ: (ap-southeast-1). Nhấn vào Create VPC. Chọn CIDR và chọn CIDR là 10.0.0.0/23 Nhấn vào Create PVC để hoàn thành. Tạo subnets Chúng ta sẽ tạo 8 subnets. 2 public subnets để cho client có thể thực hiện các cuộc gọi APIs. 2 private application subnets nơi các services sẽ được đặt. 2 private middleware subnets nơi để chạy MSK, Elasticache, Debezium (EC2). 2 private database subnet nơi đặt các database của các services. { \u0026#34;public_subnets\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;my-public-subnet-a-1a\u0026#34;, \u0026#34;availability_zone\u0026#34;: \u0026#34;ap-southeast-1a\u0026#34;, \u0026#34;ipv4_cidr\u0026#34;: \u0026#34;10.0.0.0/26\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;my-public-subnet-b-1b\u0026#34;, \u0026#34;availability_zone\u0026#34;: \u0026#34;ap-southeast-1b\u0026#34;, \u0026#34;ipv4_cidr\u0026#34;: \u0026#34;10.0.0.64/26\u0026#34; }, ], \u0026#34;private_application_subnets\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;my-private-application-subnet-a-1b\u0026#34;, \u0026#34;availability_zone\u0026#34;: \u0026#34;ap-southeast-1b\u0026#34;, \u0026#34;ipv4_cidr\u0026#34;: \u0026#34;10.0.0.128/26\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;my-private-application-subnet-b-1c\u0026#34;, \u0026#34;availability_zone\u0026#34;: \u0026#34;ap-southeast-1c\u0026#34;, \u0026#34;ipv4_cidr\u0026#34;: \u0026#34;10.0.0.192/26\u0026#34; }, ], \u0026#34;private_middleware_subnets\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;my-private-middleware-subnet-b-1c\u0026#34;, \u0026#34;availability_zone\u0026#34;: \u0026#34;ap-southeast-1c\u0026#34;, \u0026#34;ipv4_cidr\u0026#34;: \u0026#34;10.0.1.64/26\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;my-private-middleware-subnet-a-1b\u0026#34;, \u0026#34;availability_zone\u0026#34;: \u0026#34;ap-southeast-1b\u0026#34;, \u0026#34;ipv4_cidr\u0026#34;: \u0026#34;10.0.1.0/26\u0026#34; }, ], \u0026#34;private_database_subnets\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;my-private-database-subnet-a-1a\u0026#34;, \u0026#34;availability_zone\u0026#34;: \u0026#34;ap-southeast-1a\u0026#34;, \u0026#34;ipv4_cidr\u0026#34;: \u0026#34;10.0.1.128/26\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;my-private-database-subnet-a-1c\u0026#34;, \u0026#34;availability_zone\u0026#34;: \u0026#34;ap-southeast-1c\u0026#34;, \u0026#34;ipv4_cidr\u0026#34;: \u0026#34;10.0.1.192/26\u0026#34; }, ], } Tạo Route tables Chúng ta sẽ tạo 2 route tables. Tạo 1 route table tên là public_route (các public subnets sẽ sử dụng route table này). Tạo 1 route table tên là private_route (các private subnets sẽ sử dụng route table nay). private_route sẽ không có route cho Destion là 0.0.0.0/0 đến target là Internet gateway. Chúng ta sẽ chỉ cho các tài nguyên trong private subnets giao tiếp với internet thông qua NAT gateway. Đưa các subnets phù hợp vào route table. Tạo NAT gateway Vào VPC Console. Select NAT gateways → Create NAT gateway. Đặt tên Chọn subnet (Chọn subnet có route table không có Destination là 0.0.0.0/0 và có target là Internet gateway hay đó chính là private subnet). Chỉnh sửa Route table của private subnet. Kết quả Bây giờ chúng ta đã hoàn thành việc tạo mạng thành công để chúng ta có thể tách biệt các tài nguyên vào các subnet khác nhau\nKong gatewway, bastion host sẽ nằm ở public subnets. Các ứng dụng backend sẽ nằm ở private application subnet. MSK, Elasticache, Debezium (EC2) sẽ nằm ở private middleware subnet. RDS sẽ nằm ở private database subnet. Đây là bước đầu tiên để chúng ta có thể xây dựng 1 kiến trúc hướng sự kiện trên AWS.\n"
},
{
	"uri": "//localhost:1313/2-creating-first-applications-at-ps/",
	"title": "Xây dựng các ứng dụng đầu tiên ở Public Subnet",
	"tags": [],
	"description": "",
	"content": "Nội dung:\nTổng quan Định nghĩa Tạo Kong gateway Tạo Bastionhost Cài đặt Kong gateway Tổng kết Tổng quan Trong bước này chúng ta sẽ xây dựng các ứng dụng ở Public Subnet:\nKong gateway (đây là cửa ngỏ để client giao tiếp với các ứng dụng ở private application subnet mà không giao tiếp trực tiếp với các ứng dụng ở private application subnet). Bastion host (đây là 1 EC2 instance để chúng ta có thể truy cập gián tiếp vào các tài nguyên trong private subnets, vì các tài nguyên trong private subnets sẽ không có public ip, hay cũng sẽ có security group không cho truy cập từ bên ngoài vào). Định nghĩa Kong Gateway: là một thành phần trung gian nằm giữa client và các backend service, có vai trò như một \u0026ldquo;cổng ra vào\u0026rdquo; (gateway). Nó nhận request từ phía client, rồi định tuyến, xác thực, ghi log, và chuyển tiếp đến service nội bộ tương ứng.\nBastion host: là một EC2 instance đặc biệt, đóng vai trò như một cửa ngõ (gateway) để bạn có thể truy cập SSH vào các instance nằm trong private subnet – những máy mà không có IP public và không thể truy cập trực tiếp từ Internet.\nTạo Kong gateway Đi vào EC2 console. Nhấn vào Launch instance. Đặt tên (kong_gateway). Chúng ta nên tạo Key pair (đặt tên là kong_gateway). Chọn VPC (VPC mà chúng ta đã tạo ở bước trước). Đặt instance này ở public subnet. Tạo mới Sercurity group mới (đăt tên là kong_gateway_sg) và chúng ta nên sửa đổi Sercurity group này như trong ảnh. Tôi khuyên bạn nên chỉ cho phép cổng 8001 được truy cập bởi 1 số ip nhất định. Và cuối cùng là nhấn Launch instance. Giải thích Cổng 8000: Đây là cổng chính mà client (người dùng cuối hoặc ứng dụng bên ngoài) sử dụng để gửi các yêu cầu đến các dịch vụ backend trong private application subnet. Cổng 8001: Đây là cổng cho phép bạn quản lý cấu hình của Kong, như thêm/xoá/định nghĩa các route, service, plugin\u0026hellip; Tạo Bastionhost Đi vào EC2 console. Nhấn vào Launch instance. Đặt tên (bastion_host). Chúng ta nên tạo Key pair (đặt tên là bastion_host). Chọn VPC (VPC mà chúng ta đã tạo ở bước trước). Đặt instance này ở public subnet. Tạo mới Sercurity group mới (đăt tên là bastion_host_sg) và chúng ta chỉ mở cổng 22 để chúng ta có thể SSH vào instance này. Và cũng giống như kong_gateway thì ta cũng nên để cổng 22 được truy cập bởi 1 số ip nhất định. Và cuối cùng là nhấn Launch instance. Cài đặt Kong gateway SSH vào EC2 có tên là kong_gateway. Cài đặt Docker. # Cập nhật hệ thống sudo dnf update -y # Cài đặt Docker sudo dnf install docker -y # Khởi động Docker service sudo systemctl start docker sudo systemctl enable docker # Thêm user vào docker group sudo usermod -a -G docker ec2-user # Logout và login lại để áp dụng thay đổi group exit Cài đặt Docker Compose. # Cài đặt Docker Compose sudo curl -L \u0026#34;https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose Tạo file docker-compose bằng câu lệnh nano docker-compose.yml. version: \u0026#39;3.8\u0026#39; services: # PostgreSQL Database cho Kong kong-database: image: postgres:13 container_name: kong-database environment: POSTGRES_USER: kong POSTGRES_PASSWORD: kong POSTGRES_DB: kong ports: - \u0026#34;5432:5432\u0026#34; volumes: - kong_data:/var/lib/postgresql/data networks: - kong-net restart: unless-stopped # Kong Database Migration kong-migration: image: kong/kong-gateway:3.4 container_name: kong-migration command: \u0026#34;kong migrations bootstrap\u0026#34; environment: KONG_DATABASE: postgres KONG_PG_HOST: kong-database KONG_PG_USER: kong KONG_PG_PASSWORD: kong KONG_PG_DATABASE: kong depends_on: - kong-database networks: - kong-net restart: on-failure # Kong Gateway kong: image: kong/kong-gateway:3.4 container_name: kong-gateway environment: KONG_DATABASE: postgres KONG_PG_HOST: kong-database KONG_PG_USER: kong KONG_PG_PASSWORD: kong KONG_PG_DATABASE: kong KONG_PROXY_ACCESS_LOG: /dev/stdout KONG_ADMIN_ACCESS_LOG: /dev/stdout KONG_PROXY_ERROR_LOG: /dev/stderr KONG_ADMIN_ERROR_LOG: /dev/stderr KONG_ADMIN_LISTEN: 0.0.0.0:8001 KONG_ADMIN_GUI_URL: http://localhost:8002 ports: - \u0026#34;8000:8000\u0026#34; # Proxy port HTTP - \u0026#34;8001:8001\u0026#34; # Admin API port - \u0026#34;8443:8443\u0026#34; # Proxy port HTTPS - \u0026#34;8444:8444\u0026#34; # Admin API HTTPS port - \u0026#34;8002:8002\u0026#34; # Kong Manager (GUI) depends_on: - kong-migration networks: - kong-net restart: unless-stopped volumes: kong_data: networks: kong-net: driver: bridge Khởi động Kong gateway # Khởi động các container docker-compose up -d # Kiểm tra trạng thái containers docker-compose ps # Xem logs nếu cần docker-compose logs kong Xác nhận cài đặt # Kiểm tra Kong Admin API curl -i http://localhost:8001/ # Kiểm tra Kong Proxy curl -i http://localhost:8000/ Tổng kết Trong bước này, chúng ta đã thiết lập được hai thành phần quan trọng trong Public Subnet của kiến trúc mạng AWS:\nKong Gateway: đóng vai trò như một API Gateway, giúp quản lý và định tuyến các request từ client tới các dịch vụ backend nằm trong Private Subnet một cách an toàn và linh hoạt. Việc cài đặt Kong bằng Docker và Docker Compose giúp quá trình triển khai dễ dàng, nhanh chóng và có thể tái sử dụng.\nBastion Host: cho phép chúng ta truy cập các EC2 instance trong Private Subnet thông qua SSH một cách gián tiếp, đảm bảo nguyên tắc zero trust trong bảo mật mạng.\nViệc cấu hình đúng Security Group, Subnet, và hiểu vai trò từng thành phần là điều then chốt giúp hệ thống của bạn vừa bảo mật vừa dễ dàng mở rộng trong tương lai.\n"
},
{
	"uri": "//localhost:1313/3-creating-database-at-pds/",
	"title": "Tạo các database ở Private Database Subnet",
	"tags": [],
	"description": "",
	"content": "Nội dung:\nTổng quan Định nghĩa Tạo RDS PostgreSQL (No replication) Tạo RDS PostgreSQL Replication Chỉnh sửa Security group của cho các Database ở Private Database Subnet Tổng quan Trong bước này chúng ta sẽ xây dựng các database ở Private Database Subnet và database chúng ta sử dụng cho bài thực hành này là PostgreSQL.\nĐịnh nghĩa Amazon RDS (Relational Database Service): một dịch vụ cơ sở dữ liệu quan hệ được quản lý của AWS, giúp bạn dễ dàng thiết lập, vận hành và mở rộng một cơ sở dữ liệu quan hệ trên đám mây mà không cần phải tự quản lý hạ tầng máy chủ, backup, patch, replication, scaling\u0026hellip;. Logical replication: Logical Replication trong PostgreSQL là một cơ chế sao chép dữ liệu dựa trên các thay đổi logic (thao tác INSERT/UPDATE/DELETE) của dữ liệu (row-level), thay vì sao chép toàn bộ khối dữ liệu vật lý (physical block changes) như Physical Replication (Streaming Replication). Nó cho phép sao chép có chọn lọc một hoặc nhiều bảng (table-level) giữa các PostgreSQL database. Tạo RDS PostgreSQL No Replication Đi vào RDS console. Nhấn vào Create database. Thực hiện cấu hình theo như trong ảnh. Và cuối cùng nhấn vào Create database. Chúng ta sẽ tạo các database tên là bmt_user, bmt_product, bmt_showtime với cấu hình như trên.\nTạo RDS PostgreSQL Replication Đi vào RDS console. Đi vào Dashboard -\u0026gt; Parameter groups. Nhấn vào Create parameter group. Tạo Parameter group với Engine Type là PostgreSQL và Parameter group family là postgres17. Nhấn vào Create. Sau đó ta sẽ chỉnh sửa 1 số Parameters của Parameter group vừa mới tạo. Tham số Giá trị Ghi chú wal_level logical Bắt buộc để hỗ trợ logical replication max_replication_slots 4 hoặc cao hơn Số slot replication Debezium có thể sử dụng max_wal_senders 4 hoặc cao hơn Cho phép bao nhiêu tiến trình gửi WAL wal_keep_size 512MB (hoặc nhiều hơn) Giữ WAL lâu hơn đề phòng Debezium chậm đọc track_commit_timestamp on (nếu bạn cần tính toán độ trễ, không bắt buộc) Chúng ta sẽ tạo database cùng với cấu hình như trước nhưng chỉ khác ở cấu hình Cuối cùng là nhấn vào Create database. Chúng ta sẽ tiếp tục tạo các database tên là bmt_order, bmt_payment với cấu hình như trước và với Parameter group đã tạo.\nChỉnh sửa Security group của cho các Database ở Private Database Subnet Vì các databse cũng chỉ sử dụng chung 1 Security group nên ta sẽ chỉnh sửa như bên dưới.\nTại sao lại có bước này? Chúng ta cần phải thực hiện bước này để cho các ứng dụng ở subnet khác có thể truy cập vào PostgreSQL ở cổng 5432.\nChúng ta cần phải mở cổng 5432 cho Security group của Bastion host để chúng ta có thể truy cập vào database xem dữ liệu. Chúng ta cũng cần phải mở cổng 5432 cho Security group của các ứng dụng backend được triển khai ở Private application subnet để ứng dụng backend có thể truy cập vào database để thực hiện các tác vụ CRUD. Kết quả mong đợi Sau khi tạo RDS thì chúng ta phải đợi từ 5 tới 10 phút để cho việc tạo tài nguyên hoàn tất. Chúng ta sẽ cần lấy Endpoint và cần phải nhớ Password và Master username chúng ta đã đặt khi tạo RDS.\n"
},
{
	"uri": "//localhost:1313/4-creating-resources-at-pms/",
	"title": "Tạo các tài nguyên ở Private Middleware Subnet",
	"tags": [],
	"description": "",
	"content": "Nội dung:\nTổng quan Định nghĩa Tại sao ta nên sử dụng MSK? Chỉnh sửa Security group cho các tài nguyên trong Private Middleware Subnet Tạo MSK Tạo Elasticache Cài đặt Debezium Truy cập vào MSK Tổng kết Tổng quan Trong bước này chúng ta sẽ tạo các tài nguyên và đặt chúng nằm ở Private Middleware Subnet. Và chúng ta có thể truy cập MSK thông qua Bastion host.\nĐịnh nghĩa Amazon ElastiCache: một dịch vụ caching (bộ nhớ đệm) được quản lý hoàn toàn (fully managed) trong AWS, giúp tạo, vận hành và mở rộng các kho lưu trữ dữ liệu trong bộ nhớ (in-memory data store) một cách dễ dàng và hiệu quả. Mục tiêu chính của nó là cải thiện hiệu suất ứng dụng bằng cách giảm tải cho cơ sở dữ liệu chính (database) và cung cấp khả năng truy xuất dữ liệu cực nhanh. Amazon MSK (Managed Streaming for Apache Kafka): dịch vụ quản lý hoàn toàn (fully managed) của AWS giúp bạn triển khai, vận hành và mở rộng các cluster Apache Kafka để xử lý dữ liệu streaming (luồng dữ liệu) thời gian thực mà không cần tự quản lý cơ sở hạ tầng phức tạp của Kafka. Debezium: một công cụ nguồn mở (open-source) chuyên dụng cho Change Data Capture (CDC), giúp theo dõi và ghi lại mọi thay đổi dữ liệu (INSERT, UPDATE, DELETE) trong cơ sở dữ liệu quan hệ theo thời gian thực, sau đó phát chúng dưới dạng sự kiện (events) đến các hệ thống streaming như Apache Kafka. Tại sao ta nên sử dụng MSK? Việc triển khai Kafka trên AWS giúp chúng ta giải quyết được những vấn đề sau:\nTriển khai Kafka thủ công đòi hỏi kiến thức sâu, tốn công vận hành (cài đặt, cấu hình, giám sát, vá lỗi, scaling\u0026hellip;). MSK tự động hóa các tác vụ này, giúp bạn tập trung vào xử lý dữ liệu thay vì quản lý hạ tầng. Fully Managed: AWS tự động cài đặt, vá lỗi, backup, monitoring (qua CloudWatch), nâng cấp phiên bản Kafka. High Availability: Triển khai Multi-AZ, tự động phục hồi node lỗi, đảm bảo độ tin cậy 99.9%. Security: Hỗ trợ mã hóa dữ liệu (in-transit/at-rest), VPC, IAM, SSL/TLS, SASL/SCRAM. Scalability: Thêm/bớt broker, thay đổi loại instance, tự động cân bằng tải (auto rebalance partitions). Tương thích Kafka: Sử dụng client Kafka chuẩn, hỗ trợ Kafka Connect, MirrorMaker, Schema Registry. Serverless Option (MSK Serverless): Không cần quản lý capacity, tự động scale dựa trên lưu lượng, trả tiền theo sử dụng. Chỉnh sửa Security group cho các tài nguyên trong Private Middleware Subnet Giải thích:\nPORT 6379: Chúng ta sẽ cho phép Security group của các tài nguyên trong Private Application Subnet có thể kết nối tới Elasticache của chúng ta. PORT 9092: Chúng ta sẽ cho phép Security group của các tài nguyên trong Private Application Subnet, Bastion host (để có thể thực hiện 1 số các vụ như xem Topic, tạo Topic,\u0026hellip;), và cuối cùng là cho phép Debezium nằm trong cùng subnet có thể kết nối tới MSK. Tạo MSK Đi vào Amazon MSK console. Nhấn vào Create MSK. Bước 1 Bước 2 Bước 3 2 bước còn lại thì để mặc định. Nhấn vào Create cluster. Tạo Elasticache Đi vào Elasticache Dashboard. Chọn Redis OSS caches -\u0026gt; Create cache. Chọn cấu hình như trong ảnh. Ở Step 2 chúng ta sẽ để tất cả các tùy chọn mặc định và sẽ chọn Security Group giống như khi tạo MSK. Ở Step 3 nhấn vào Create. Cài đặt Debezium Đi vào EC2 console. Nhấn vào Launch instance. Đặt tên (debezium). Chúng ta nên tạo Key pair (đặt tên là debezium). Chọn VPC (VPC mà chúng ta đã tạo ở bước trước). Đặt instance này ở private middleware subnet. Chọn Security Group cho Instance này giống như khi tạo Elasticache. Sau khi tạo xong EC2 Instance cho Debezium thì chúng ta sẽ SSH vào instance này thông qua Bastion host và thực hiện 1 số cài đặt. Sau khoảng 10-20 phút thì quá trình tạo MSK sẽ hoàn tất và chúng ta sẽ cần truy cập vào MSK để lấy thông tin về Bootstrap Server và trong hình ảnh thì ta sẽ lấy thông tin từ Private endpoint (single-VPC).\n# Cập nhật hệ thống sudo dnf update -y # Cài đặt Java 11 hoặc 17 (Debezium yêu cầu) sudo dnf install -y java-11-openjdk java-11-openjdk-devel # Kiểm tra Java version java -version Tạo file docker-compose.yml bằng cú pháp nano docker-compose.yml.\nversion: \u0026#39;2\u0026#39; services: debezium: image: debezium/connect:2.6 container_name: debezium ports: - \u0026#34;8083:8083\u0026#34; environment: BOOTSTRAP_SERVERS: \u0026lt;YOUR_BOOTSTRAP_SERVERS\u0026gt; GROUP_ID: debezium-connect-cluster CONFIG_STORAGE_TOPIC: debezium_connect_configs OFFSET_STORAGE_TOPIC: debezium_connect_offsets STATUS_STORAGE_TOPIC: debezium_connect_statuses KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter PLUGIN_PATH: /kafka/connect,/debezium-plugins CONNECT_REST_ADVERTISED_HOST_NAME: debezium CONNECT_GROUP_ID: debezium-connect-cluster CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1 CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1 CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1 CONNECT_PLUGIN_PATH: /kafka/connect,/debezium-plugins CONNECT_LOG4J_ROOT_LOGLEVEL: INFO volumes: volumes: - /tmp/debezium-data:/kafka/data restart: unless-stopped Chúng ta sẽ thực hiện API này để đăng ký một Connector. Và chúng ta sẽ đăng kí các connector cho bmt_order, bmt_payment database. Và điều quan trọng là trọng là khi tạo database thì chúng ta phải chạy câu lệnh CREATE PUBLICATION order_dbz_publication FOR TABLE outboxes;. Và trong ứng dụng backend của tôi đã có script tự động tạo database và cũng có thực hiện câu lệnh CREATE PUBLICATION order_dbz_publication FOR TABLE outboxes;.\nGiải thích câu lệnh CREATE PUBLICATION order_dbz_publication FOR TABLE outboxes;:\nCREATE PUBLICATION: Tạo một publication mới (một nhóm các bảng được theo dõi thay đổi). order_dbz_publication: Tên của publication bạn tự đặt. FOR TABLE outboxes: Chỉ định bảng outboxes sẽ được đưa vào publication (theo dõi thay đổi INSERT/UPDATE/DELETE). curl -X POST http://localhost:8083/connectors \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;name\u0026#34;: \u0026#34;YOUR_CONNECTOR_NAME\u0026#34;, \u0026#34;config\u0026#34;: { \u0026#34;connector.class\u0026#34;: \u0026#34;io.debezium.connector.postgresql.PostgresConnector\u0026#34;, \u0026#34;database.hostname\u0026#34;: \u0026#34;your-db-host\u0026#34;, \u0026#34;database.port\u0026#34;: \u0026#34;5432\u0026#34;, \u0026#34;database.user\u0026#34;: \u0026#34;youruser\u0026#34;, \u0026#34;database.password\u0026#34;: \u0026#34;yourpassword\u0026#34;, \u0026#34;database.dbname\u0026#34;: \u0026#34;yourdbname\u0026#34;, \u0026#34;database.server.name\u0026#34;: \u0026#34;pgserver1\u0026#34;, \u0026#34;plugin.name\u0026#34;: \u0026#34;pgoutput\u0026#34;, \u0026#34;slot.name\u0026#34;: \u0026#34;debezium\u0026#34;, \u0026#34;publication.name\u0026#34;: \u0026#34;debezium_pub\u0026#34;, \u0026#34;table.include.list\u0026#34;: \u0026#34;public.users\u0026#34;, \u0026#34;tombstones.on.delete\u0026#34;: \u0026#34;false\u0026#34; } }\u0026#39; Sau khi thực hiện API trên thì Debezium sẽ tự động tạo Kafka topic theo cú pháp: \u0026lt;topic.prefix\u0026gt;.\u0026lt;schema\u0026gt;.\u0026lt;table\u0026gt; . Và sau khi đăng kí các connectors thì chúng ta sẽ xem danh sách các connectors bằng câu lệnh curl http://localhost:8083/connectors.\nTruy cập vào MSK Để có thể truy cập vào MSK chúng ta nên truy cập thông qua Bastion host. Chúng ta sẽ SSH vào Bastion host. Và thực hiện câu lệnh bên dưới.\n# Tải Kafka 3.6.0 và giải nén nó ra thư mục hiện tại curl https://downloads.apache.org/kafka/3.6.0/kafka_2.13-3.6.0.tgz | tar -xz Và khi muốn truy cập vào MSK thì chúng ta cần phải thực hiện câu lệnh cd kafka_2.13-3.6.0. Để xem các Topic trong MSK thì chúng ta thực hiện câu lệnh bin/kafka-topics.sh \u0026ndash;bootstrap-server \u0026lt;YOUR_BOOTSTRAP_SERVER\u0026gt;:9092 \u0026ndash;list. Nếu không có Topic nào có dạng \u0026lt;topic.prefix\u0026gt;.\u0026lt;schema\u0026gt;.\u0026lt;table\u0026gt;. Lí do là MSK mặc định không tự tạo topic, nếu chúng ta không bật auto.create.topics.enable trên broker. Và chúng ta sẽ tạo thủ công với câu lệnh:\n./bin/kafka-topics.sh --create --bootstrap-server \u0026lt;YOUR_BOOTSTRAP_SERVER\u0026gt;:9092 --topic bmt_payment.public.outboxes --partitions 1 --replication-factor 2 Sau đó chúng ta sẽ kiểm tra lại và sẽ thấy các Topic với dạng \u0026lt;topic.prefix\u0026gt;.\u0026lt;schema\u0026gt;.\u0026lt;table\u0026gt; .\nTổng kết Trong bước này, chúng ta đã triển khai thành công các tài nguyên quan trọng nằm trong Private Middleware Subnet, bao gồm:\nAmazon MSK (Managed Streaming for Apache Kafka): Giải pháp xử lý dữ liệu dạng luồng (streaming) được quản lý hoàn toàn, giúp giảm tải việc vận hành hạ tầng Kafka thủ công. Amazon ElastiCache (Redis): Dịch vụ bộ nhớ đệm giúp tăng tốc độ truy xuất dữ liệu và giảm tải cho cơ sở dữ liệu chính. Debezium: Công cụ CDC (Change Data Capture) giúp phát hiện và đẩy các thay đổi dữ liệu từ cơ sở dữ liệu PostgreSQL lên Kafka. Chúng ta cũng đã:\nCấu hình lại các Security Group để đảm bảo các kết nối an toàn và hợp lý giữa các thành phần như application, middleware, bastion host và database. Tạo EC2 instance chạy Debezium trong private subnet, truy cập thông qua Bastion host để thực hiện cấu hình và kiểm tra. Cài đặt Kafka CLI để tương tác với MSK từ bastion host. Hiểu rõ rằng MSK không tự động tạo topic, và trong trường hợp cần thiết, chúng ta có thể tạo topic thủ công để phù hợp với luồng dữ liệu của Debezium. Toàn bộ bước này đặt nền tảng vững chắc để các dịch vụ trong private subnet có thể giao tiếp qua Kafka, caching qua Redis, và đảm bảo dữ liệu luôn được đồng bộ hóa theo thời gian thực nhờ Debezium.\n"
},
{
	"uri": "//localhost:1313/5-creating-resources-at-pas/",
	"title": "Tạo các tài nguyên ở Private Application Subnet",
	"tags": [],
	"description": "",
	"content": "Nội dung:\nTổng quan Tạo ứng dụng backend bằng EC2 Cài đặt service Khởi động User Service Khởi động Mail Service Khởi động Product Service Khởi động Upload Service Khởi động Showtime Service Khởi động Order Service Khởi động Payment Service Tổng kết Tổng quan Trong bước này chúng ta sẽ tạo các tài nguyên và đặt chúng nằm ở Private Application Subnet. Và chúng ta sẽ lấy các ứng dụng backend từ Docker hub.\nTạo ứng dụng backend bằng EC2 Chúng ta sẽ tạo các ứng dụng backend lần lượt là: bmt_user, bmt_mail, bmt_product, bmt_showtime, bmt_upload, bmt_order, bmt_payment.\nĐi vào EC2 console. Nhấn vào Launch instance. Đặt tên theo service. Chúng ta nên tạo Key pair (đặt tên theo service). Chọn VPC (VPC mà chúng ta đã tạo ở bước trước). Đặt instance này ở public subnet. Tạo mới Sercurity group mới (đăt tên là application_sg) và chúng ta nên sửa đổi Sercurity group này như trong ảnh. Giải thích:\nPORT 5002: Đây là port sẽ chạy ở User service. Và sẽ cho phép SG của EC2 Kong gateway có thể truy cập vào. PORT 5003: Đây là port sẽ chạy ở Product service. Và sẽ cho phép SG của EC2 Kong gateway có thể truy cập vào. PORT 5005: Đây là port sẽ chạy ở Showtime service. Và sẽ cho phép SG của EC2 Kong gateway có thể truy cập vào. PORT 5006: Đây là port sẽ chạy ở Order service. Và sẽ cho phép SG của EC2 Kong gateway có thể truy cập vào. PORT 5007: Đây là port sẽ chạy ở Payment service. Và sẽ cho phép SG của EC2 Kong gateway có thể truy cập vào. PORT 50033: Đây là port sẽ chạy ở Product service và cho RPC server. Và sẽ cho phép SG của chính EC2 có thể kết nối tới port này. PORT 50055: Đây là port sẽ chạy ở Showtime service và cho RPC server. Và sẽ cho phép SG của chính EC2 có thể kết nối tới port này. Cài đặt service Truy cập vào từng EC2 của Private application subnet.\nCài đặt Docker.\n# Cập nhật hệ thống sudo dnf update -y # Cài đặt Docker sudo dnf install docker -y # Khởi động Docker service sudo systemctl start docker sudo systemctl enable docker # Thêm user vào docker group sudo usermod -a -G docker ec2-user # Logout và login lại để áp dụng thay đổi group exit Sau khi cài đặt Docker thành công thì ta sẽ lấy các image về. Truy cập vào https://hub.docker.com/repository/docker/nguyenhuyk3/bmt/tags để có thể lấy các iamges.\nChúng ta sẽ lấy các image bằng câu lệnh docker pull nguyenhuyk3/bmt:\u0026lt;SERVICE_NAME\u0026gt;. Với mỗi EC2 instance thì sẽ là một service.\nKhởi động User Service Chúng ta sẽ tạo file app.env bằng câu lệnh nano /home/ec2-user/app.env với nội dung bên dưới. SERVER_PORT=5002 SERCET_KEY=EoLC-@*\u0026amp;!4mNtV+?dpu0`C+dAwKmKy1X ISS=a404f1c1-7058-4af7-976a-3aaf6f742fe8 FIXED_IV=aBcD1EfGhIjK2LmN KEY_FOR_ADMIN=bba7f5cd-b619-4e46-bd7e-17cdad1bda11 RDS_DB_URL=postgres://\u0026lt;YOUR_USERNAME\u0026gt;:\u0026lt;YOURR_PASSWORD\u0026gt;@\u0026lt;YOUR_HOST\u0026gt;:5432/\u0026lt;YOUR_DATABASE_NAME\u0026gt;?sslmode=require Giải thích\nSERVER_PORT: Đây là port mà User Service sẽ chạy. SERCET_KEY: Trong JWT (JSON Web Token), SECRET_KEY là một chuỗi bí mật dùng để ký và xác minh token trong thuật toán ký đối xứng, ví dụ như HS256, HS384, HS512. ISS: Trường iss là viết tắt của Issuer (người phát hành token). Nó biểu thị ai đã tạo ra token đó – thường là một hệ thống xác thực như Auth Server, Identity Provider, hoặc một service backend. Và chúng ta sẽ lấy được nó khi đăng kí thành công JWT credential trong Kong. FIXED_IV: Trong AES (Advanced Encryption Standard), thuật ngữ fixed IV (Initialization Vector cố định) đề cập đến việc sử dụng cùng một IV cho nhiều lần mã hóa. KEY_FOR_ADMIN: Đây là key dùng để đăng kí tài khoản với quyền Admin. RDS_DB_URL: Đây là một PostgreSQL connection string. Và nội dung của connection string chúng ta sẽ lấy ở RDS khi tạo PostgreSQL. Chúng ta sẽ tạo file prod.yaml bằng câu lệnh nano /home/ec2-user/prod.yaml với nội dung bên dưới. database: host: \u0026lt;YOUR_DB_HOST_AT_RDS\u0026gt; port: 5432 username: \u0026#34;\u0026lt;YOUR_USERNAME\u0026#34; password: \u0026#34;\u0026lt;YOUR_PASSWORD\u0026gt;\u0026#34; db_name: \u0026#34;bmt_user\u0026#34; max_idle_conns: 10 max_open_conns: 100 conn_max_lifetime: 3600 redis: host: \u0026#34;\u0026lt;YOUR_REDIS_HOST_AT_ELASTICACHE\u0026gt;\u0026#34; port: 6379 password: \u0026#34;\u0026#34; database: 0 kafka: kafka_broker_1: \u0026#34;\u0026lt;YOUR_KAFKA_BOOTRAP_SERVER_AT_MSK\u0026gt;\u0026#34; kafka_broker_2: \u0026#34;\u0026lt;YOUR_KAFKA_BOOTRAP_SERVER_AT_MSK\u0026gt;\u0026#34; Sau khi tạo thành công 2 file trên thì chúng ta sẽ chạy câu lệnh docker run -d \\ --env-file /home/ec2-user/app.env \\ -v /home/ec2-user/prod.yaml:/app/local.yaml \\ -p 5002:5002 \\ --name user_service \\ nguyenhuyk3/bmt:bmt_user Chúng ta sẽ chạy câu lệnh docker logs -f \u0026lt;CONTAINER_ID\u0026gt; và sẽ thấy được màn hình như bên dưới. Khởi động Mail Service Chúng ta sẽ tạo file prod.yaml bằng câu lệnh nano /home/ec2-user/prod.yaml với nội dung bên dưới. mail: host: \u0026#34;\u0026#34; # Host SMTP của Amazon SES tại khu vực ap-southeast-1 (Singapore). port: \u0026#34;2587\u0026#34; # Cổng kết nối SMTP. username: \u0026#34;\u0026#34; # SMTP Username. password: \u0026#34;\u0026#34; # SMTP Password. kafka: kafka_broker_1: \u0026#34;\u0026lt;YOUR_KAFKA_BOOTRAP_SERVER_AT_MSK\u0026gt;\u0026#34; kafka_broker_2: \u0026#34;\u0026lt;YOUR_KAFKA_BOOTRAP_SERVER_AT_MSK\u0026gt;\u0026#34; zap_log: log_level: debug file_log_name: \u0026#34;./storages/logs/bmt_mail_service.log\u0026#34; max_size: 500 max_backups: 3 max_age: 28 compress: true Chúng ta sẽ tạo file app.env bằng câu lệnh nano /home/ec2-user/app.env với nội dung bên dưới. FROM_EMAIL= \u0026#34;\u0026#34; # Đây là email dùng để gửi mail. Sau khi tạo thành công 2 file trên thì chúng ta sẽ chạy câu lệnh docker run -d \\ --env-file /home/ec2-user/app.env \\ -v /home/ec2-user/prod.yaml:/app/local.yaml \\ --name mail_service \\ nguyenhuyk3/bmt:bmt_mail Chúng ta sẽ thấy màn hình console chạy cũng tương tự như ở User service. Khởi động Product Service Chúng ta sẽ tạo file prod.yaml bằng câu lệnh nano /home/ec2-user/prod.yaml với nội dung bên dưới. database: host: \u0026lt;YOUR_DB_HOST_AT_RDS\u0026gt; port: 5432 username: \u0026#34;\u0026lt;YOUR_USERNAME\u0026#34; password: \u0026#34;\u0026lt;YOUR_PASSWORD\u0026gt;\u0026#34; db_name: \u0026#34;bmt_product\u0026#34; max_idle_conns: 10 max_open_conns: 100 conn_max_lifetime: 3600 redis: host: \u0026#34;\u0026lt;YOUR_REDIS_HOST_AT_ELASTICACHE\u0026gt;\u0026#34; port: 6379 password: \u0026#34;\u0026#34; database: 0 kafka: kafka_broker_1: \u0026#34;\u0026lt;YOUR_KAFKA_BOOTRAP_SERVER_AT_MSK\u0026gt;\u0026#34; kafka_broker_2: \u0026#34;\u0026lt;YOUR_KAFKA_BOOTRAP_SERVER_AT_MSK\u0026gt;\u0026#34; s3: aws_access_key_id: \u0026#34;\u0026#34; # Chúng ta sẽ vào IAM Console để lấy AWS ACCESS KEY ID. aws_sercet_access_key_id: \u0026#34;\u0026#34; # Chúng ta sẽ vào IAM Console để lấy AWS SERCET ACCESS KEY ID. aws_region: \u0026#34;ap-southeast-1\u0026#34; film_bucket_name: \u0026#34;bmt-s3-main-bucket\u0026#34; # Chúng ta sẽ vào tạo 1 S3 bucket với tên như mô tả. thumbnail_film_bucket_name: \u0026#34;bmt-s3-thumbnail-bucket\u0026#34; # Chúng ta sẽ vào tạo 1 S3 bucket với tên như mô tả. Chúng ta sẽ tạo file app.env bằng câu lệnh nano /home/ec2-user/app.env với nội dung bên dưới. SERVER_PORT=5003 # Đây là port của Product service. RPC_SERVER_PORT=50033 # Đây là port dùng để chạy RPC server. RDS_DB_URL=postgres://\u0026lt;YOUR_USERNAME\u0026gt;:\u0026lt;YOURR_PASSWORD\u0026gt;@\u0026lt;YOUR_HOST\u0026gt;:5432/\u0026lt;YOUR_DATABASE_NAME\u0026gt;?sslmode=require Sau khi tạo thành công 2 file trên thì chúng ta sẽ chạy câu lệnh docker run -d \\ --env-file /home/ec2-user/app.env \\ -v /home/ec2-user/prod.yaml:/app/local.yaml \\ -p 5003:5003 -p 50033:50033 \\ --name product_service \\ nguyenhuyk3/bmt:bmt_product Chúng ta sẽ thấy màn hình console chạy cũng tương tự như ở User service. Khởi động Upload Service Chúng ta sẽ tạo file prod.yaml bằng câu lệnh nano /home/ec2-user/prod.yaml với nội dung bên dưới. kafka: kafka_broker_1: \u0026#34;\u0026lt;YOUR_KAFKA_BOOTRAP_SERVER_AT_MSK\u0026gt;\u0026#34; kafka_broker_2: \u0026#34;\u0026lt;YOUR_KAFKA_BOOTRAP_SERVER_AT_MSK\u0026gt;\u0026#34; s3: aws_access_key_id: \u0026#34;\u0026#34; # Chúng ta sẽ vào IAM Console để lấy AWS ACCESS KEY ID. aws_sercet_access_key_id: \u0026#34;\u0026#34; # Chúng ta sẽ vào IAM Console để lấy AWS SERCET ACCESS KEY ID. aws_region: \u0026#34;ap-southeast-1\u0026#34; film_bucket_name: \u0026#34;bmt-s3-main-bucket\u0026#34; # Chúng ta sẽ vào tạo 1 S3 bucket với tên như mô tả. sqs: queue_url: \u0026#34;\u0026#34; # Chúng ta sẽ tạo 1 SQS Queue và lấy URL của nó. Chúng ta sẽ tạo 1 Policy để cho phép service của chúng ta có thể sử dụng SQS bên trong EC2. Và chúng ta sẽ tạo Role với Policy vừa tạo. Sau đó chúng ta sẽ thêm Role vừa tạo cho EC2 deloy Upload Service. Và chúng ta sẽ tạo Policy như bên dưới. { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;sqs:ReceiveMessage\u0026#34;, \u0026#34;sqs:DeleteMessage\u0026#34;, \u0026#34;sqs:GetQueueAttributes\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;ARN_OF_SQS\u0026#34; } ] } Chúng ta sẽ tạo file app.env bằng câu lệnh nano /home/ec2-user/app.env với nội dung bên dưới. AWS_REGION=ap-southeast-1 Sau khi tạo thành công 2 file trên thì chúng ta sẽ chạy câu lệnh docker run -d \\ --env-file /home/ec2-user/app.env \\ -v /home/ec2-user/prod.yaml:/app/local.yaml \\ --name upload_service \\ nguyenhuyk3/bmt:upload_service Chúng ta sẽ thấy màn hình console chạy cũng tương tự như ở User service. Khởi động Showtime Service Chúng ta sẽ tạo file prod.yaml bằng câu lệnh nano /home/ec2-user/prod.yaml với nội dung bên dưới. database: host: \u0026lt;YOUR_DB_HOST_AT_RDS\u0026gt; port: 5432 username: \u0026#34;\u0026lt;YOUR_USERNAME\u0026#34; password: \u0026#34;\u0026lt;YOUR_PASSWORD\u0026gt;\u0026#34; db_name: \u0026#34;bmt_showtime\u0026#34; max_idle_conns: 10 max_open_conns: 100 conn_max_lifetime: 3600 redis: host: \u0026#34;\u0026lt;YOUR_REDIS_HOST_AT_ELASTICACHE\u0026gt;\u0026#34; port: 6379 password: \u0026#34;\u0026#34; database: 0 kafka: kafka_broker_1: \u0026#34;\u0026lt;YOUR_KAFKA_BOOTRAP_SERVER_AT_MSK\u0026gt;\u0026#34; kafka_broker_2: \u0026#34;\u0026lt;YOUR_KAFKA_BOOTRAP_SERVER_AT_MSK\u0026gt;\u0026#34; Chúng ta sẽ tạo file app.env bằng câu lệnh nano /home/ec2-user/app.env với nội dung bên dưới. SERVER_PORT=5005 # Đây là port mà service sẽ chạy. PRODUCT_RPC_SERVER_PORT=50033 # Vì Order Service cần lấy 1 số tài nguyên từ Product Service qua gRPC. SHOWTIME_RPC_SERVER_PORT=50055 # Vì Order Service cần lấy 1 số tài nguyên từ Showtime Service qua gRPC. RDS_DB_URL=postgres://\u0026lt;YOUR_USERNAME\u0026gt;:\u0026lt;YOURR_PASSWORD\u0026gt;@\u0026lt;YOUR_HOST\u0026gt;:5432/\u0026lt;YOUR_DATABASE_NAME\u0026gt;?sslmode=require Sau khi tạo thành công 2 file trên thì chúng ta sẽ chạy câu lệnh. docker run -d \\ --env-file /home/ec2-user/app.env \\ -v /home/ec2-user/prod.yaml:/app/local.yaml \\ -p 5005:5005 \\ --name showtime_service \\ nguyenhuyk3/bmt:bmt_showtime Chúng ta sẽ thấy màn hình console chạy cũng tương tự như ở User service. Khởi động Order Service Chúng ta sẽ tạo file prod.yaml bằng câu lệnh nano /home/ec2-user/prod.yaml với nội dung bên dưới. database: host: \u0026lt;YOUR_DB_HOST_AT_RDS\u0026gt; port: 5432 username: \u0026#34;\u0026lt;YOUR_USERNAME\u0026#34; password: \u0026#34;\u0026lt;YOUR_PASSWORD\u0026gt;\u0026#34; db_name: \u0026#34;bmt_order\u0026#34; max_idle_conns: 10 max_open_conns: 100 conn_max_lifetime: 3600 redis: host: \u0026#34;\u0026lt;YOUR_REDIS_HOST_AT_ELASTICACHE\u0026gt;\u0026#34; port: 6379 password: \u0026#34;\u0026#34; database: 0 kafka: kafka_broker_1: \u0026#34;\u0026lt;YOUR_KAFKA_BOOTRAP_SERVER_AT_MSK\u0026gt;\u0026#34; kafka_broker_2: \u0026#34;\u0026lt;YOUR_KAFKA_BOOTRAP_SERVER_AT_MSK\u0026gt;\u0026#34; Chúng ta sẽ tạo file app.env bằng câu lệnh nano /home/ec2-user/app.env với nội dung bên dưới. SERVER_PORT=5006 # Đây là port mà service sẽ chạy. PRODUCT_RPC_SERVER_PORT=50033 # Vì Order Service cần lấy 1 số tài nguyên từ Product Service qua gRPC. SHOWTIME_RPC_SERVER_PORT=50055 # Vì Order Service cần lấy 1 số tài nguyên từ Showtime Service qua gRPC. RDS_DB_URL=postgres://\u0026lt;YOUR_USERNAME\u0026gt;:\u0026lt;YOURR_PASSWORD\u0026gt;@\u0026lt;YOUR_HOST\u0026gt;:5432/\u0026lt;YOUR_DATABASE_NAME\u0026gt;?sslmode=require Sau khi tạo thành công 2 file trên thì chúng ta sẽ chạy câu lệnh. docker run -d \\ --env-file /home/ec2-user/app.env \\ -v /home/ec2-user/prod.yaml:/app/local.yaml \\ -p 5006:5006 \\ --name order_service \\ nguyenhuyk3/bmt:bmt_order Chúng ta sẽ thấy màn hình console chạy cũng tương tự như ở User service. Khởi động Payment Service Chúng ta sẽ tạo file prod.yaml bằng câu lệnh nano /home/ec2-user/prod.yaml với nội dung bên dưới. database: host: \u0026lt;YOUR_DB_HOST_AT_RDS\u0026gt; port: 5432 username: \u0026#34;\u0026lt;YOUR_USERNAME\u0026#34; password: \u0026#34;\u0026lt;YOUR_PASSWORD\u0026gt;\u0026#34; db_name: \u0026#34;bmt_order\u0026#34; max_idle_conns: 10 max_open_conns: 100 conn_max_lifetime: 3600 redis: host: \u0026#34;\u0026lt;YOUR_REDIS_HOST_AT_ELASTICACHE\u0026gt;\u0026#34; port: 6379 password: \u0026#34;\u0026#34; database: 0 kafka: kafka_broker_1: \u0026#34;\u0026lt;YOUR_KAFKA_BOOTRAP_SERVER_AT_MSK\u0026gt;\u0026#34; kafka_broker_2: \u0026#34;\u0026lt;YOUR_KAFKA_BOOTRAP_SERVER_AT_MSK\u0026gt;\u0026#34; momo: end_point: \u0026#34;https://test-payment.momo.vn/v2/gateway/api/create\u0026#34; partner_code: \u0026#34;MOMO\u0026#34; access_key: \u0026#34;F8BBA842ECF85\u0026#34; secret_key: \u0026#34;K951B6PE1waDMi640xX08PD3vg6EkVlz\u0026#34; redirect_url: \u0026#34;http://\u0026lt;PUBLIC_IP_OF_KONG_GATEWAY\u0026gt;:8000/v1/momo/customer/verify_payment\u0026#34; # Đây là api sẽ được gọi sau khi người dùng thanh toán MOMO. Và nó sẽ xử lí theo trường hợp thanh toán thành công hay thất bại. mobile_redirect_url: \u0026#34;bmt://payment-result\u0026#34; ipn_url: \u0026#34;http://\u0026lt;PUBLIC_IP_OF_KONG_GATEWAY\u0026gt;/v1/momo/customer/verify_payment\u0026#34; Chúng ta sẽ tạo file app.env bằng câu lệnh nano /home/ec2-user/app.env với nội dung bên dưới. SERVER_PORT=5007 # Đây là port mà service sẽ chạy RDS_DB_URL=postgres://\u0026lt;YOUR_USERNAME\u0026gt;:\u0026lt;YOURR_PASSWORD\u0026gt;@\u0026lt;YOUR_HOST\u0026gt;:5432/\u0026lt;YOUR_DATABASE_NAME\u0026gt;?sslmode=require Sau khi tạo thành công 2 file trên thì chúng ta sẽ chạy câu lệnh. docker run -d \\ --env-file /home/ec2-user/app.env \\ -v /home/ec2-user/prod.yaml:/app/local.yaml \\ -p 5007:5007 \\ --name order_payment \\ nguyenhuyk3/bmt:bmt_payment Chúng ta sẽ thấy màn hình console chạy cũng tương tự như ở User service. Tổng kết Chúng ta đã hoàn thành việc khởi tạo các Services nằm trong Private Application Subnet. Bạn có thể thấy 1 số apis khi các service được chạy. Trong ảnh trên bạn có thể thấy những services có apis riêng của nó nhưng bạn không thể gọi được vì hiện tại nó đang nằm trong 1 private subnet. Và chúng ta muốn giao tiếp với nó chúng ta sẽ thực hiện thông qua Kong gateway. "
},
{
	"uri": "//localhost:1313/6-routing-api-with-kong-gateway/",
	"title": "Routing API với Kong Gateway",
	"tags": [],
	"description": "",
	"content": "Nội dung:\nTổng quan Các bước thực hiện Tạo service Tạo route Tạo JWT plugin Tạo Pre function plugin Tổng kết Tổng quan Trong phần này chúng ta sẽ thực hiện 1 số api để định tuyến API với mục đích là để cho máy khách có thể gọi API tới các dịch vụ của chúng ta mà sẽ không gọi trực tiếp đến các dịch vụ nằm trong Private Applicaton Subnet. Đây cũng là 1 thiết kế phổ biến trong kiến trúc microservices.\nCác bước thực hiện Để máy khách có thể gọi tới 1 api của ứng dụng backend của chúng ta thì chúng ta sẽ thực hiện những bước sau đây:\nTạo service Tao route Ngoài ra đối với những API cần xác thực JWT thì chúng ta sẽ tạo JWT plugin cho route này hay kiểm tra 1 số thông tin từ Token JWT như kiểm tra Role có phù hợp với hành động này hay không thì chúng ta sẽ tạo Pre-function.\nTạo service Chúng ta sẽ vào Post man và thực hiện API để tạo service Chúng ta sẽ gọi api http://\u0026lt;PUBLIC_IP_OF_KONG_GATEWAY\u0026gt;:8001/services với phương thức POST (Tôi khuyên là chúng ta nên cấu hình Security group của EC2 đang host Kong gateway được truy cập vào cổng 8001 với 1 số ip nhất định như chinh ip của máy mình): { \u0026#34;name\u0026#34;: \u0026#34;\u0026lt;NAME_OF_SERVICE\u0026gt;\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;\u0026lt;PRIVATE_IP_OF_SERVICE\u0026gt;\u0026#34;, \u0026#34;port\u0026#34;: \u0026#34;\u0026lt;PORT_OF_SERVICE\u0026gt;\u0026#34;, // Chúng ta sẽ sử dụng kiểu số ở đây \u0026#34;path\u0026#34;: \u0026#34;PATH_OF_API\u0026#34;, \u0026#34;retries\u0026#34;: 5, \u0026#34;connect_timeout\u0026#34;: 60000, \u0026#34;write_timeout\u0026#34;: 60000, \u0026#34;read_timeout\u0026#34;: 60000 } Tạo route Chúng ta sẽ vào Post man và thực hiện API để tạo service Chúng ta sẽ gọi api http://\u0026lt;PUBLIC_IP_OF_KONG_GATEWAY\u0026gt;:8001/routes với phương thức POST: { \u0026#34;name\u0026#34;: \u0026#34;\u0026lt;NAME_OF_ROUTE\u0026gt;\u0026#34;, \u0026#34;service\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;\u0026lt;NAME_OF_SERVICE\u0026gt;\u0026#34; }, \u0026#34;protocols\u0026#34;: [\u0026#34;http\u0026#34;], // Chúng ta có thể chọn nhiều protocols khác như http, https, gRPC,... \u0026#34;methods\u0026#34;: [\u0026#34;GET\u0026#34;], // Chúng ta có thể thêm nhiều methods khác như GET, POST, PATHC,... \u0026#34;paths\u0026#34;: [\u0026#34;\u0026lt;PATH_OF_API_THAT_WE_WANT_CLIENT_USE\u0026gt;\u0026#34;], \u0026#34;strip_path\u0026#34;: true, \u0026#34;preserve_host\u0026#34;: false, \u0026#34;request_buffering\u0026#34;: true, \u0026#34;response_buffering\u0026#34;: true, \u0026#34;https_redirect_status_code\u0026#34;: 426, \u0026#34;regex_priority\u0026#34;: 0, \u0026#34;path_handling\u0026#34;: \u0026#34;v0\u0026#34; } Tạo JWT plugin Trước khi tạo JWT thì chúng ta sẽ tạo 1 Consummer trước. Consummer là gì?\nLà đối tượng đại diện cho client truy cập API, như:\nỨng dụng di động. Frontend web. Đối tác (partner system). Một người dùng cụ thể. Tạo Consummer với API http://\u0026lt;PUBLIC_IP_OF_KONG_GATEWAY\u0026gt;:8001/consumers với phương POST: { \u0026#34;username\u0026#34;: \u0026#34;jwt\u0026#34;, \u0026#34;custom_id\u0026#34;: \u0026#34;f0a221b9-d74f-44ac-93b6-50c8fd4259a7\u0026#34; } Tạo JWT Plugin với API http://\u0026lt;PUBLIC_IP_OF_KONG_GATEWAY\u0026gt;:8001/routes/\u0026lt;ID_OF_ROUTE\u0026gt;/plugins với phương thức POST. Và để lấy \u0026lt;ID_OF_ROUTE\u0026gt; chúng ta sẽ thực hiện API http://\u0026lt;PUBLIC_IP_OF_KONG_GATEWAY\u0026gt;:8001/routes với phương thức GET. { \u0026#34;name\u0026#34;: \u0026#34;jwt\u0026#34;, \u0026#34;config\u0026#34;: { \u0026#34;run_on_preflight\u0026#34;: true, \u0026#34;secret_is_base64\u0026#34;: false, \u0026#34;key_claim_name\u0026#34;: \u0026#34;iss\u0026#34;, \u0026#34;claims_to_verify\u0026#34;: [\u0026#34;exp\u0026#34;], \u0026#34;anonymous\u0026#34;: null, \u0026#34;maximum_expiration\u0026#34;: 0, \u0026#34;header_names\u0026#34;: [\u0026#34;authorization\u0026#34;] }, \u0026#34;enabled\u0026#34;: true } Tạo Pre function plugin Chúng ta sẽ thực hiện API http://\u0026lt;PUBLIC_IP_OF_KONG_GATEWAY\u0026gt;:8001/routes/\u0026lt;ID_OF_ROUTE\u0026gt;/plugins. { \u0026#34;name\u0026#34;: \u0026#34;pre-function\u0026#34;, \u0026#34;config\u0026#34;: { \u0026#34;access\u0026#34;: [ \u0026#34;-- Get JWT token from header Authorization\\nlocal auth_header = kong.request.get_header(\\\u0026#34;Authorization\\\u0026#34;)\\nif not auth_header then\\n return kong.response.exit(401, { message = \\\u0026#34;missing Authorization header\\\u0026#34; })\\nend\\n\\n-- Get token from \\\u0026#34;Bearer \u0026lt;token\u0026gt;\\\u0026#34;\\nlocal token = auth_header:match(\\\u0026#34;^Bearer%s+(.+)$\\\u0026#34;)\\nif not token then\\n return kong.response.exit(401, { message = \\\u0026#34;invalid Token format\\\u0026#34; })\\nend\\n\\n-- Split token into 3 parts: header.payload.signature\\nlocal token_parts = {}\\nfor part in token:gmatch(\\\u0026#34;[^.]+\\\u0026#34;) do\\n table.insert(token_parts, part)\\nend\\n\\nif #token_parts ~= 3 then\\n return kong.response.exit(401, { message = \\\u0026#34;invalid JWT token structure\\\u0026#34; })\\nend\\n\\n-- Decode payload (middle part of JWT)\\nlocal payload_str = ngx.decode_base64(token_parts[2])\\nif not payload_str then\\n return kong.response.exit(401, { message = \\\u0026#34;failed to decode JWT payload\\\u0026#34; })\\nend\\n\\n-- Extract \\\u0026#34;role\\\u0026#34; from JSON payload\\nlocal role = payload_str:match(\u0026#39;\\\u0026#34;role\\\u0026#34;%s*:%s*\\\u0026#34;([^\\\u0026#34;]+)\\\u0026#34;\u0026#39;)\\nif not role then\\n return kong.response.exit(403, { message = \\\u0026#34;missing role in token\\\u0026#34; })\\nend\\n\\n-- Check role, only allow customer\\nif role ~= \\\u0026#34;customer\\\u0026#34; then\\n return kong.response.exit(403, { message = \\\u0026#34;access denied: requires customer role\\\u0026#34; })\\nend\\n\\nreturn\u0026#34; ] // Đây là code viết bằng lua và field access là nơi chúng ta sẽ đặt những code lua cho những mục đích kiểm tra của chúng ta. Và code trên kiểm tra Token JWT có chứa role là customer hay không và gán nó vòa Header của APi. } } Tổng kết Trong phần này, chúng ta đã tìm hiểu cách sử dụng Kong Gateway để định tuyến và bảo vệ API trong môi trường kiến trúc microservices, cụ thể:\nTạo Service: khai báo dịch vụ backend thực tế mà Kong sẽ định tuyến đến. Tạo Route: cấu hình đường dẫn API mà client sẽ gọi, và ánh xạ nó đến service tương ứng. Tạo Consumer: đại diện cho client hoặc hệ thống sử dụng API, dùng để gắn thông tin xác thực. Cấu hình JWT Plugin: đảm bảo chỉ client có JWT hợp lệ mới có thể truy cập API, giúp tăng cường bảo mật. Cấu hình Pre-function Plugin: viết logic Lua tùy chỉnh để kiểm tra thêm thông tin trong JWT (ví dụ: kiểm tra quyền truy cập thông qua trường role trong payload). Những bước này giúp đảm bảo rằng:\nHệ thống của bạn được định tuyến hợp lý. Các dịch vụ backend nằm trong Private Subnet vẫn có thể được truy cập một cách an toàn và kiểm soát được thông qua Kong Gateway. -Bạn có thể dễ dàng kiểm soát, giới hạn và giám sát các request đến hệ thống. 👉 Đây là cách tiếp cận chuẩn và phổ biến trong việc triển khai các API Gateway cho hệ thống microservices hiện đại.\n"
},
{
	"uri": "//localhost:1313/7-perform-apis-of-backend-applications/",
	"title": "Thực hiện các API của các ứng dụng Backend",
	"tags": [],
	"description": "",
	"content": "Nội dung:\nTổng quan Thực hiện đăng kí tài khoản người dùng Thực hiện thêm phim Thực hiện đặt vé xem phim Tổng kết Tổng quan Sau khi thực hiện xong các bước trên thì trong phần này chúng sẽ thực hiện gọi các APIs với tư cách là 1 máy khách.\nThực hiện đăng kí tài khoản người dùng Thực hiện đăng kí người dùng với email\nChúng ta có thể thấy rằng sau khi người đăng kí với email huykimcuong5@gmail.com thì ở Mail service nhận được message từ Kafka và thực hiện việc gửi mail với mã OTP.\nHoàn thành các bước tiếp theo\nCó thể thấy chúng ta đã thực hiện 3 APIs để hoàn thành việc đăng kí.\nThực hiện thêm phim Đăng nhập tài khoản với quyền admin.\nThêm phim với quyền admin.\nKhi thực hiện thêm phim thì ảnh và trailer của phim sẽ được tải lên S3 và S3 sẽ đưa sự kiện Put Object vào SNS và SQS sẽ nhận message từ SNS. Và upload service sẽ nhận message từ SQS.\nVà upload service sẽ ghi message vào Kafka với những thông tin cần thiết để cho product service cập nhập URL của ảnh và trailer vào database.\nVà ta truy cập vào database để xem những thông tin về ảnh và trailer của phim.\nCũng tương tự như với FAB (Food And Beverage)\nỞ product service thì sẽ nhận message từ upload service khi chúng ta tải ảnh lên S3 thành công.\nThực hiện đặt vé xem phim Trước tiên chúng ta sẽ phải thêm showtime mới. Và chúng ta sẽ thực hiện 1 API gọi là Realease showtime. Sau đó chúng ta và database kiểm tra ghế cho showtime đó.\nKiểm tra ghế có showtime id = 3.\nChúng ta sẽ thực hiện API để đặt ghế với showtime id = 3. Sau khi đặt ghế thành công thì sẽ được trả order id về.\nSau khi gọi API tạo payment URL với order id vừa được tạo khi thực hiện API tạo order.\nSau khi thanh toán thành công thì payment service trả về thông tin của vé xem phim.\nVà chúng ta sẽ cùng kiểm tra các topic mà chúng ta đã tạo thủ công với tên lần lượt là: bmt_payment.public.outboxes, bmt_order.public.outboxes.\nNhư có thể thấy trong ảnh thì trong cả 2 topic thì đều có những message, chính những message này đã được những service khác tiêu thụ và xử lí theo nội dung của message.\nTổng kết Trong phần này, chúng ta đã đóng vai trò là một máy khách để thực hiện toàn bộ luồng sử dụng của hệ thống backend, từ việc đăng ký tài khoản người dùng đến đặt vé xem phim và xử lý thanh toán. Qua từng bước, chúng ta đã thấy rõ:\nLuồng đăng ký tài khoản được thực hiện thông qua chuỗi các API liên quan đến xác thực và xác minh OTP. Sau khi người dùng đăng ký, Mail Service đã nhận message từ Kafka và gửi OTP đến email thông qua Amazon SES. Luồng thêm phim với quyền admin bao gồm việc tải ảnh và trailer lên Amazon S3, nơi sự kiện PutObject kích hoạt SNS → SQS → Upload Service. Sau đó, Upload Service gửi message vào Kafka để Product Service cập nhật URL hình ảnh và video vào cơ sở dữ liệu. Luồng đặt vé xem phim bắt đầu từ việc tạo showtime, kiểm tra ghế theo showtime_id, thực hiện đặt vé, tạo đơn hàng và nhận URL thanh toán. Sau khi thanh toán thành công, hệ thống đã tạo vé xem phim và lưu thông tin liên quan. Cơ chế giao tiếp giữa các service sử dụng Kafka và SQS giúp hệ thống hoạt động theo mô hình event-driven, đảm bảo sự tách biệt giữa các thành phần và khả năng mở rộng linh hoạt. Cuối cùng, chúng ta cũng đã xác nhận rằng các message được ghi vào các Kafka topic như bmt_payment.public.outboxes và bmt_order.public.outboxes đã được các service tiêu thụ thành công để xử lý các nghiệp vụ liên quan. Phần thực hành này giúp ta hiểu rõ hơn về cách hệ thống backend vận hành trong môi trường phân tán, sử dụng các dịch vụ như Kafka, S3, SQS và API Gateway một cách hiệu quả và đồng bộ.\n"
},
{
	"uri": "//localhost:1313/8-setting-up-monitoring-and-logging-with-cloudwatch/",
	"title": "Giám sát và khả năng quan sát với Amazon CloudWatch",
	"tags": [],
	"description": "",
	"content": "Amazon CloudWatch là gì? Amazon CloudWatch là dịch vụ quan sát được quản lý hoàn toàn, cung cấp dữ liệu và thông tin chi tiết hữu ích cho tài nguyên, ứng dụng và dịch vụ AWS. Dịch vụ này cho phép bạn:\nThu thập nhật ký và số liệu từ các dịch vụ AWS và ứng dụng tùy chỉnh Tạo cảnh báo dựa trên ngưỡng hoặc phát hiện bất thường Trực quan hóa dữ liệu bằng bảng điều khiển Tự động phản hồi các thay đổi bằng sự kiện và quy tắc CloudWatch đóng vai trò trung tâm trong việc chẩn đoán các sự cố vận hành và tối ưu hóa hiệu suất trong kiến trúc phân tán, hướng sự kiện hoặc không máy chủ.\nTại sao nên sử dụng Logging và CloudWatch? Việc thiết lập chế độ ghi nhật ký và khả năng quan sát phù hợp với CloudWatch là rất cần thiết vì những lý do sau:\nKhắc phục sự cố và Gỡ lỗi: Nhật ký giúp bạn theo dõi các vấn đề đến từng chức năng hoặc sự kiện cụ thể, cho phép bạn giải quyết lỗi nhanh hơn.\nGiám sát Hoạt động: Các số liệu cho phép bạn theo dõi tình trạng hệ thống — bao gồm tỷ lệ gọi hàm, độ trễ và tần suất lỗi.\nPhát hiện Lỗi: Các cảnh báo sẽ chủ động thông báo cho bạn về các vấn đề như tồn đọng tin nhắn trong hàng đợi, điều tiết hoặc tràn DLQ.\nKiểm toán và Tuân thủ: Nhật ký đóng vai trò là bản ghi lịch sử về hành vi của hệ thống để theo dõi kiểm toán và đánh giá sau sự cố.\nTối ưu hóa Hiệu suất: Các số liệu của CloudWatch có thể được sử dụng để phân tích các điểm nghẽn, tối ưu hóa việc sử dụng máy tính/bộ nhớ và giảm chi phí.\nMục tiêu Thiết lập hệ thống giám sát tập trung (centralized monitoring) và khả năng quan sát (observability) cho các thành phần của ứng dụng không máy chủ (serverless) bằng cách tận dụng Amazon CloudWatch để thu thập logs, metrics và sự kiện từ nhiều dịch vụ khác nhau trong hệ sinh thái AWS.\nCác thành phần được giám sát:\nAmazon EC2 Metrics CPU, Memory, Disk I/O, Network In/Out (qua CloudWatch Agent). Logs Application logs (ví dụ: logs từ ứng dụng Node.js, Go, Java\u0026hellip;). System logs /var/log/messages, /var/log/syslog, v.v. Cách triển khai: Cài CloudWatch Agent trên EC2 instance. Cấu hình thu thập cả metrics và logs, gửi về CloudWatch. Amazon MSK (Managed Kafka) Metrics: Broker-level (CPU, memory, disk). Kafka-level (bytes in/out, replication lag, under-replicated partitions). Logs Kafka broker logs (controller logs, server logs…). Cách triển khai: Bật enhanced monitoring và log delivery về CloudWatch Logs khi tạo MSK Cluster hoặc cập nhật sau. Dùng các biểu đồ và alarm để theo dõi tình trạng cluster. Amazon RDS (PostgreSQL, MySQL, Aurora\u0026hellip;) Metrics CPU, FreeableMemory, DatabaseConnections, Read/Write Latency. Logs Error log, General log, Slow query log. Cách triển khai: Bật tính năng gửi logs về CloudWatch Logs trong cấu hình RDS. Sử dụng CloudWatch Dashboard để hiển thị các metric quan trọng. Amazon ElastiCache (Redis/Memcached) Metrics CPUUtilization, CurrConnections, Evictions, CacheHits/Misses, ReplicationLag. Logs ❌ Không hỗ trợ CloudWatch Logs trực tiếp (Redis logs không tự gửi lên được). Cách triển khai: Sử dụng các metric sẵn có trong CloudWatch để tạo dashboard và cảnh báo. Nếu cần log chi tiết như Redis Slowlog, phải thu thập thủ công. Các thành phần kiến trúc đang được quan sát Các thành phần AWS sau đây cần được tích hợp với CloudWatch:\nThành phần Các số liệu và nhật ký cần giám sát Amazon EC2 - CPUUtilization, MemoryUsage, Disk I/O, Network I/O- Application logs- System logs (/var/log/messages, /var/log/syslog) Amazon MSK - BytesInPerSec, BytesOutPerSec, UnderReplicatedPartitions, ReplicationLag- Kafka broker logs (controller, server, state-change logs) Amazon RDS - CPUUtilization, FreeableMemory, ReadLatency, WriteLatency, DatabaseConnections- Error logs, Slow query logs, General logs Amazon ElastiCache - CPUUtilization, CurrConnections, Evictions, CacheHits/Misses, ReplicationLag- ❌ Không hỗ trợ gửi logs trực tiếp về CloudWatch Xây dựng bảng điều khiển CloudWatch tập trung Tạo bảng thông tin tùy chỉnh trong (CloudWatch → Bảng điều khiển) với các tiện ích sau:\nWidget Title Metrics Displayed EC2 System Health CPUUtilization, MemoryUsage, DiskReadBytes, DiskWriteBytes, NetworkIn, NetworkOut EC2 Application Logs Log stream từ các ứng dụng đang chạy trên EC2 (theo thời gian thực) RDS Performance CPUUtilization, FreeableMemory, ReadLatency, WriteLatency, DatabaseConnections RDS Error \u0026amp; Slow Queries Error log \u0026amp; Slow query log (truy xuất từ CloudWatch Logs Insights) MSK Cluster Throughput BytesInPerSec, BytesOutPerSec, UnderReplicatedPartitions, ReplicationLag MSK Broker Logs Kafka broker logs (controller, server, state-change logs) ElastiCache Usage \u0026amp; Replication CPUUtilization, CurrConnections, CacheHits, CacheMisses, ReplicationLag Application Errors (Across Services) Truy vấn lỗi HTTP 4xx/5xx từ CloudWatch Logs Insights (có thể áp dụng cho API Gateway, Lambda, EC2\u0026hellip;) Tổng quan Hệ thống Biểu đồ tổng hợp trạng thái hoạt động của tất cả thành phần (OK/ALARM/INSUFFICIENT) Sử dụng các hình ảnh trực quan này để có cái nhìn tổng quan theo thời gian thực về tình trạng và hiệu suất của hệ thống.\nKết quả mong đợi Sau khi triển khai các bước trên:\nTất cả các thành phần ứng dụng liên tục truyền nhật ký đến CloudWatch. Cảnh báo phát hiện và cảnh báo về lỗi hệ thống và độ trễ. Bảng điều khiển cho phép phân tích hiệu suất và độ tin cậy theo thời gian thực. Nhật ký và số liệu cho phép gỡ lỗi hiệu quả, phân tích nguyên nhân gốc rễ và giám sát hoạt động. "
},
{
	"uri": "//localhost:1313/9-optimizing-for-cost-and-performance/",
	"title": "Tối ưu hóa chi phí và hiệu suất",
	"tags": [],
	"description": "",
	"content": "Giới thiệu Tối ưu hóa chi phí và hiệu suất là một phần thiết yếu trong vận hành hệ thống trên AWS, giúp bạn cân bằng giữa khả năng mở rộng, tính sẵn sàng và ngân sách. Trong chương này, chúng ta sẽ tập trung vào việc tối ưu cho các dịch vụ đã sử dụng trong hệ thống: Amazon EC2, Amazon MSK, Amazon RDS, và Amazon ElastiCache.\nAmazon EC2 – Linh hoạt theo nhu cầu Chi phí Sử dụng Auto Scaling Group để chỉ khởi tạo số lượng instance cần thiết tùy theo tải (scale in/out). Chọn đúng loại instance (ví dụ: t4g, m6g, c6i\u0026hellip;) dựa trên workload (compute/memory/storage-optimized). Dùng Spot Instances cho các workload không cần đảm bảo (batch job, worker\u0026hellip;). Tắt các instance nhàn rỗi hoặc lên lịch dừng theo giờ hành chính với AWS Instance Scheduler. Sử dụng Savings Plans hoặc Reserved Instances nếu có workload cố định lâu dài. Hiệu suất Cài đặt CloudWatch Agent để theo dõi CPU, Memory, Disk I/O. Dùng Elastic Load Balancer (ELB) để phân phối đều lưu lượng đến các instance. Cân nhắc sử dụng Amazon EBS gp3 để tăng IOPS/dung lượng linh hoạt mà vẫn tiết kiệm. Amazon MSK – Kafka được quản lý Chi phí Chọn loại instance phù hợp cho broker (ví dụ: kafka.t3.small cho môi trường dev/test). Giảm số lượng broker khi tải nhẹ và không cần khả năng chịu lỗi cao. Tắt các cluster không dùng hoặc chuyển sang môi trường serverless nếu workload không liên tục. Sử dụng Kafka Topic Retention Policy hợp lý để giới hạn dung lượng lưu trữ (ví dụ: chỉ giữ 3 ngày). Hiệu suất Bật Enhanced Monitoring để theo dõi chi tiết throughput, replication lag. Tối ưu cấu hình Kafka như batch.size, linger.ms cho producer và fetch.min.bytes cho consumer. Tránh Under-replicated partitions bằng cách phân bổ phân vùng đều giữa các broker. Dùng CloudWatch Dashboard để theo dõi real-time tình trạng cluster. Amazon RDS – Cơ sở dữ liệu quan trọng Chi phí Chọn đúng loại instance (db.t4g, db.m6g cho workloads vừa phải). Dùng Aurora Serverless v2 nếu tải không liên tục. Tự động dừng RDS khi không dùng (cho môi trường dev/test). Xóa snapshots không cần thiết để tiết kiệm chi phí lưu trữ. Sử dụng Reserved Instances nếu có nhu cầu chạy dài hạn. Hiệu suất Bật Performance Insights để xác định truy vấn chậm, lock, wait events\u0026hellip; Tối ưu index và query thường xuyên dựa trên slow query log. Thiết lập Read Replicas để phân tải đọc, giảm áp lực node chính. Theo dõi các chỉ số như ReadLatency, WriteLatency, DatabaseConnections. Amazon ElastiCache – Cache hiệu quả, chi phí hợp lý Chi phí Chọn đúng engine và kích thước node (cache.t4g.small cho test/dev, cache.m6g.large cho production). Giảm số lượng node trong cụm nếu cache hit ratio cao và tải nhẹ. Không bật Multi-AZ nếu không cần thiết (đối với workload không yêu cầu HA). Xem xét thời gian TTL của keys để tránh giữ dữ liệu quá lâu gây tốn bộ nhớ. Hiệu suất Theo dõi CacheHitRate, Evictions, CurrConnections từ CloudWatch. Tối ưu TTL phù hợp để tránh eviction sớm hoặc giữ cache dư thừa. Dùng cluster mode để scale horizontal nếu cần hiệu suất cao. Dùng Redis slowlog để phát hiện các truy vấn tốn thời gian. Tổng kết Việc tối ưu hóa không chỉ giúp giảm chi phí mà còn cải thiện hiệu suất hệ thống đáng kể. Một số nguyên tắc chung:\nGiám sát liên tục để xác định điểm nghẽn và lãng phí. Tự động hóa tắt/mở tài nguyên khi không sử dụng. Chọn đúng công cụ và kiến trúc phù hợp với từng loại workload. Hãy xem việc tối ưu chi phí như một quá trình liên tục, đi đôi với sự phát triển và mở rộng của hệ thống.\n"
},
{
	"uri": "//localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]